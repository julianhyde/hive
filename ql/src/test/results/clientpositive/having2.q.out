PREHOOK: query: CREATE TABLE TestV1_Staples (
      Item_Count INT,
      Ship_Priority STRING,
      Order_Priority STRING,
      Order_Status STRING,
      Order_Quantity DOUBLE,
      Sales_Total DOUBLE,
      Discount DOUBLE,
      Tax_Rate DOUBLE,
      Ship_Mode STRING,
      Fill_Time DOUBLE,
      Gross_Profit DOUBLE,
      Price DOUBLE,
      Ship_Handle_Cost DOUBLE,
      Employee_Name STRING,
      Employee_Dept STRING,
      Manager_Name STRING,
      Employee_Yrs_Exp DOUBLE,
      Employee_Salary DOUBLE,
      Customer_Name STRING,
      Customer_State STRING,
      Call_Center_Region STRING,
      Customer_Balance DOUBLE,
      Customer_Segment STRING,
      Prod_Type1 STRING,
      Prod_Type2 STRING,
      Prod_Type3 STRING,
      Prod_Type4 STRING,
      Product_Name STRING,
      Product_Container STRING,
      Ship_Promo STRING,
      Supplier_Name STRING,
      Supplier_Balance DOUBLE,
      Supplier_Region STRING,
      Supplier_State STRING,
      Order_ID STRING,
      Order_Year INT,
      Order_Month INT,
      Order_Day INT,
      Order_Date_ STRING,
      Order_Quarter STRING,
      Product_Base_Margin DOUBLE,
      Product_ID STRING,
      Receive_Time DOUBLE,
      Received_Date_ STRING,
      Ship_Date_ STRING,
      Ship_Charge DOUBLE,
      Total_Cycle_Time DOUBLE,
      Product_In_Stock STRING,
      PID INT,
      Market_Segment STRING
      )
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@TestV1_Staples
POSTHOOK: query: CREATE TABLE TestV1_Staples (
      Item_Count INT,
      Ship_Priority STRING,
      Order_Priority STRING,
      Order_Status STRING,
      Order_Quantity DOUBLE,
      Sales_Total DOUBLE,
      Discount DOUBLE,
      Tax_Rate DOUBLE,
      Ship_Mode STRING,
      Fill_Time DOUBLE,
      Gross_Profit DOUBLE,
      Price DOUBLE,
      Ship_Handle_Cost DOUBLE,
      Employee_Name STRING,
      Employee_Dept STRING,
      Manager_Name STRING,
      Employee_Yrs_Exp DOUBLE,
      Employee_Salary DOUBLE,
      Customer_Name STRING,
      Customer_State STRING,
      Call_Center_Region STRING,
      Customer_Balance DOUBLE,
      Customer_Segment STRING,
      Prod_Type1 STRING,
      Prod_Type2 STRING,
      Prod_Type3 STRING,
      Prod_Type4 STRING,
      Product_Name STRING,
      Product_Container STRING,
      Ship_Promo STRING,
      Supplier_Name STRING,
      Supplier_Balance DOUBLE,
      Supplier_Region STRING,
      Supplier_State STRING,
      Order_ID STRING,
      Order_Year INT,
      Order_Month INT,
      Order_Day INT,
      Order_Date_ STRING,
      Order_Quarter STRING,
      Product_Base_Margin DOUBLE,
      Product_ID STRING,
      Receive_Time DOUBLE,
      Received_Date_ STRING,
      Ship_Date_ STRING,
      Ship_Charge DOUBLE,
      Total_Cycle_Time DOUBLE,
      Product_In_Stock STRING,
      PID INT,
      Market_Segment STRING
      )
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@TestV1_Staples
PREHOOK: query: explain
SELECT customer_name, SUM(customer_balance), SUM(order_quantity) FROM default.testv1_staples s1 GROUP BY customer_name HAVING (
(COUNT(s1.discount) <= 822) AND
(SUM(customer_balance) <= 4074689.000000041)
)
PREHOOK: type: QUERY
POSTHOOK: query: explain
SELECT customer_name, SUM(customer_balance), SUM(order_quantity) FROM default.testv1_staples s1 GROUP BY customer_name HAVING (
(COUNT(s1.discount) <= 822) AND
(SUM(customer_balance) <= 4074689.000000041)
)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: s1
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Select Operator
              expressions: order_quantity (type: double), discount (type: double), customer_name (type: string), customer_balance (type: double)
              outputColumnNames: order_quantity, discount, customer_name, customer_balance
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Group By Operator
                aggregations: sum(customer_balance), sum(order_quantity), count(discount)
                keys: customer_name (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  value expressions: _col1 (type: double), _col2 (type: double), _col3 (type: bigint)
      Reduce Operator Tree:
        Group By Operator
          aggregations: sum(VALUE._col0), sum(VALUE._col1), count(VALUE._col2)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
          Filter Operator
            predicate: ((_col1 <= 4074689.000000041) and (_col3 <= 822)) (type: boolean)
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Select Operator
              expressions: _col0 (type: string), _col1 (type: double), _col2 (type: double)
              outputColumnNames: _col0, _col1, _col2
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              File Output Operator
                compressed: false
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: explain
SELECT customer_name, SUM(customer_balance), SUM(order_quantity) FROM default.testv1_staples s1 GROUP BY customer_name HAVING (
(SUM(customer_balance) <= 4074689.000000041)
AND (COUNT(s1.discount) <= 822)
)
PREHOOK: type: QUERY
POSTHOOK: query: explain
SELECT customer_name, SUM(customer_balance), SUM(order_quantity) FROM default.testv1_staples s1 GROUP BY customer_name HAVING (
(SUM(customer_balance) <= 4074689.000000041)
AND (COUNT(s1.discount) <= 822)
)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: s1
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Select Operator
              expressions: order_quantity (type: double), discount (type: double), customer_name (type: string), customer_balance (type: double)
              outputColumnNames: order_quantity, discount, customer_name, customer_balance
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Group By Operator
                aggregations: sum(customer_balance), sum(order_quantity), count(discount)
                keys: customer_name (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  value expressions: _col1 (type: double), _col2 (type: double), _col3 (type: bigint)
      Reduce Operator Tree:
        Group By Operator
          aggregations: sum(VALUE._col0), sum(VALUE._col1), count(VALUE._col2)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
          Filter Operator
            predicate: ((_col1 <= 4074689.000000041) and (_col3 <= 822)) (type: boolean)
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Select Operator
              expressions: _col0 (type: string), _col1 (type: double), _col2 (type: double)
              outputColumnNames: _col0, _col1, _col2
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              File Output Operator
                compressed: false
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: explain
SELECT s1.customer_name FROM default.testv1_staples s1 join default.src s2 on s1.customer_name = s2.key
GROUP BY s1.customer_name
HAVING (
(SUM(s1.customer_balance) <= 4074689.000000041)
AND (AVG(s1.discount) <= 822)
AND (COUNT(s2.value) > 4)
)
PREHOOK: type: QUERY
POSTHOOK: query: explain
SELECT s1.customer_name FROM default.testv1_staples s1 join default.src s2 on s1.customer_name = s2.key
GROUP BY s1.customer_name
HAVING (
(SUM(s1.customer_balance) <= 4074689.000000041)
AND (AVG(s1.discount) <= 822)
AND (COUNT(s2.value) > 4)
)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: s1
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Filter Operator
              predicate: customer_name is not null (type: boolean)
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Select Operator
                expressions: discount (type: double), customer_name (type: string), customer_balance (type: double)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col1 (type: string)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  value expressions: _col0 (type: double), _col2 (type: double)
          TableScan
            alias: s2
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: string)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 _col1 (type: string)
            1 _col0 (type: string)
          outputColumnNames: _col0, _col1, _col2, _col4
          Statistics: Num rows: 550 Data size: 5843 Basic stats: PARTIAL Column stats: NONE
          Group By Operator
            aggregations: sum(_col2), avg(_col0), count(_col4)
            keys: _col1 (type: string)
            mode: hash
            outputColumnNames: _col0, _col1, _col2, _col3
            Statistics: Num rows: 550 Data size: 5843 Basic stats: PARTIAL Column stats: NONE
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: string)
              sort order: +
              Map-reduce partition columns: _col0 (type: string)
              Statistics: Num rows: 550 Data size: 5843 Basic stats: PARTIAL Column stats: NONE
              value expressions: _col1 (type: double), _col2 (type: struct<count:bigint,sum:double,input:double>), _col3 (type: bigint)
      Reduce Operator Tree:
        Group By Operator
          aggregations: sum(VALUE._col0), avg(VALUE._col1), count(VALUE._col2)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          Statistics: Num rows: 275 Data size: 2921 Basic stats: PARTIAL Column stats: NONE
          Filter Operator
            predicate: ((_col1 <= 4074689.000000041) and (_col2 <= 822.0) and (_col3 > 4)) (type: boolean)
            Statistics: Num rows: 10 Data size: 106 Basic stats: PARTIAL Column stats: NONE
            Select Operator
              expressions: _col0 (type: string)
              outputColumnNames: _col0
              Statistics: Num rows: 10 Data size: 106 Basic stats: PARTIAL Column stats: NONE
              File Output Operator
                compressed: false
                Statistics: Num rows: 10 Data size: 106 Basic stats: PARTIAL Column stats: NONE
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: explain
SELECT s1.customer_name FROM default.testv1_staples s1 join default.src s2 on s1.customer_name = s2.key
GROUP BY s1.customer_name, s1.customer_name
HAVING (
(SUM(s1.customer_balance) <= 4074689.000000041)
AND (AVG(s1.discount) <= 822)
AND (COUNT(s2.value) > 4)
)
PREHOOK: type: QUERY
POSTHOOK: query: explain
SELECT s1.customer_name FROM default.testv1_staples s1 join default.src s2 on s1.customer_name = s2.key
GROUP BY s1.customer_name, s1.customer_name
HAVING (
(SUM(s1.customer_balance) <= 4074689.000000041)
AND (AVG(s1.discount) <= 822)
AND (COUNT(s2.value) > 4)
)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: s1
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Filter Operator
              predicate: customer_name is not null (type: boolean)
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Select Operator
                expressions: discount (type: double), customer_name (type: string), customer_balance (type: double)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col1 (type: string)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  value expressions: _col0 (type: double), _col2 (type: double)
          TableScan
            alias: s2
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: string)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 _col1 (type: string)
            1 _col0 (type: string)
          outputColumnNames: _col0, _col1, _col2, _col4
          Statistics: Num rows: 550 Data size: 5843 Basic stats: PARTIAL Column stats: NONE
          Group By Operator
            aggregations: sum(_col2), avg(_col0), count(_col4)
            keys: _col1 (type: string)
            mode: hash
            outputColumnNames: _col0, _col1, _col2, _col3
            Statistics: Num rows: 550 Data size: 5843 Basic stats: PARTIAL Column stats: NONE
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: string)
              sort order: +
              Map-reduce partition columns: _col0 (type: string)
              Statistics: Num rows: 550 Data size: 5843 Basic stats: PARTIAL Column stats: NONE
              value expressions: _col1 (type: double), _col2 (type: struct<count:bigint,sum:double,input:double>), _col3 (type: bigint)
      Reduce Operator Tree:
        Group By Operator
          aggregations: sum(VALUE._col0), avg(VALUE._col1), count(VALUE._col2)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          Statistics: Num rows: 275 Data size: 2921 Basic stats: PARTIAL Column stats: NONE
          Select Operator
            expressions: _col0 (type: string), _col1 (type: double), _col2 (type: double), _col3 (type: bigint)
            outputColumnNames: _col1, _col2, _col3, _col4
            Statistics: Num rows: 275 Data size: 2921 Basic stats: PARTIAL Column stats: NONE
            Filter Operator
              predicate: ((_col2 <= 4074689.000000041) and (_col3 <= 822.0) and (_col4 > 4)) (type: boolean)
              Statistics: Num rows: 10 Data size: 106 Basic stats: PARTIAL Column stats: NONE
              Select Operator
                expressions: _col1 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 10 Data size: 106 Basic stats: PARTIAL Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 10 Data size: 106 Basic stats: PARTIAL Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: explain
SELECT distinct COUNT(*) AS c
FROM default.testv1_staples s1 join default.src s2 on s1.customer_name = s2.key
HAVING (
(SUM(s1.customer_balance) <= 4074689.000000041)
AND (AVG(s1.discount) <= 822)
AND (COUNT(s2.value) > 4)
)
PREHOOK: type: QUERY
POSTHOOK: query: explain
SELECT distinct COUNT(*) AS c
FROM default.testv1_staples s1 join default.src s2 on s1.customer_name = s2.key
HAVING (
(SUM(s1.customer_balance) <= 4074689.000000041)
AND (AVG(s1.discount) <= 822)
AND (COUNT(s2.value) > 4)
)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: s1
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Filter Operator
              predicate: customer_name is not null (type: boolean)
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Select Operator
                expressions: discount (type: double), customer_name (type: string), customer_balance (type: double)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col1 (type: string)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  value expressions: _col0 (type: double), _col2 (type: double)
          TableScan
            alias: s2
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: string)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 _col1 (type: string)
            1 _col0 (type: string)
          outputColumnNames: _col0, _col2, _col4
          Statistics: Num rows: 550 Data size: 5843 Basic stats: PARTIAL Column stats: NONE
          Group By Operator
            aggregations: count(), sum(_col2), avg(_col0), count(_col4)
            mode: hash
            outputColumnNames: _col0, _col1, _col2, _col3
            Statistics: Num rows: 1 Data size: 104 Basic stats: PARTIAL Column stats: NONE
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              sort order: 
              Statistics: Num rows: 1 Data size: 104 Basic stats: PARTIAL Column stats: NONE
              value expressions: _col0 (type: bigint), _col1 (type: double), _col2 (type: struct<count:bigint,sum:double,input:double>), _col3 (type: bigint)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0), sum(VALUE._col1), avg(VALUE._col2), count(VALUE._col3)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          Statistics: Num rows: 1 Data size: 104 Basic stats: PARTIAL Column stats: NONE
          Filter Operator
            predicate: ((_col1 <= 4074689.000000041) and (_col2 <= 822.0) and (_col3 > 4)) (type: boolean)
            Statistics: Num rows: 1 Data size: 104 Basic stats: PARTIAL Column stats: NONE
            Select Operator
              expressions: _col0 (type: bigint)
              outputColumnNames: _col0
              Statistics: Num rows: 1 Data size: 104 Basic stats: PARTIAL Column stats: NONE
              File Output Operator
                compressed: false
                Statistics: Num rows: 1 Data size: 104 Basic stats: PARTIAL Column stats: NONE
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: DROP TABLE IF EXISTS src
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@src
PREHOOK: Output: default@src
POSTHOOK: query: DROP TABLE IF EXISTS src
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@src
POSTHOOK: Output: default@src
PREHOOK: query: DROP TABLE IF EXISTS src1
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@src1
PREHOOK: Output: default@src1
POSTHOOK: query: DROP TABLE IF EXISTS src1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@src1
POSTHOOK: Output: default@src1
PREHOOK: query: DROP TABLE IF EXISTS src_json
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@src_json
PREHOOK: Output: default@src_json
POSTHOOK: query: DROP TABLE IF EXISTS src_json
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@src_json
POSTHOOK: Output: default@src_json
PREHOOK: query: DROP TABLE IF EXISTS src_sequencefile
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@src_sequencefile
PREHOOK: Output: default@src_sequencefile
POSTHOOK: query: DROP TABLE IF EXISTS src_sequencefile
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@src_sequencefile
POSTHOOK: Output: default@src_sequencefile
PREHOOK: query: DROP TABLE IF EXISTS src_thrift
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@src_thrift
PREHOOK: Output: default@src_thrift
POSTHOOK: query: DROP TABLE IF EXISTS src_thrift
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@src_thrift
POSTHOOK: Output: default@src_thrift
PREHOOK: query: DROP TABLE IF EXISTS srcbucket
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@srcbucket
PREHOOK: Output: default@srcbucket
POSTHOOK: query: DROP TABLE IF EXISTS srcbucket
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@srcbucket
POSTHOOK: Output: default@srcbucket
PREHOOK: query: DROP TABLE IF EXISTS srcbucket2
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@srcbucket2
PREHOOK: Output: default@srcbucket2
POSTHOOK: query: DROP TABLE IF EXISTS srcbucket2
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@srcbucket2
POSTHOOK: Output: default@srcbucket2
PREHOOK: query: DROP TABLE IF EXISTS srcpart
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@srcpart
PREHOOK: Output: default@srcpart
POSTHOOK: query: DROP TABLE IF EXISTS srcpart
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@srcpart
POSTHOOK: Output: default@srcpart
PREHOOK: query: DROP TABLE IF EXISTS primitives
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS primitives
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS dest1
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS dest1
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS dest2
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS dest2
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS dest3
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS dest3
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS dest4
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS dest4
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS dest4_sequencefile
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS dest4_sequencefile
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS dest_j1
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS dest_j1
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS dest_g1
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS dest_g1
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS dest_g2
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS dest_g2
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS fetchtask_ioexception
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS fetchtask_ioexception
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS alltypesorc
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@alltypesorc
PREHOOK: Output: default@alltypesorc
POSTHOOK: query: DROP TABLE IF EXISTS alltypesorc
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@alltypesorc
POSTHOOK: Output: default@alltypesorc
PREHOOK: query: DROP TABLE IF EXISTS alltypesparquet
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@alltypesparquet
PREHOOK: Output: default@alltypesparquet
POSTHOOK: query: DROP TABLE IF EXISTS alltypesparquet
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@alltypesparquet
POSTHOOK: Output: default@alltypesparquet
PREHOOK: query: DROP TABLE IF EXISTS cbo_t1
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@cbo_t1
PREHOOK: Output: default@cbo_t1
POSTHOOK: query: DROP TABLE IF EXISTS cbo_t1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@cbo_t1
POSTHOOK: Output: default@cbo_t1
PREHOOK: query: DROP TABLE IF EXISTS cbo_t2
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@cbo_t2
PREHOOK: Output: default@cbo_t2
POSTHOOK: query: DROP TABLE IF EXISTS cbo_t2
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@cbo_t2
POSTHOOK: Output: default@cbo_t2
PREHOOK: query: DROP TABLE IF EXISTS cbo_t3
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@cbo_t3
PREHOOK: Output: default@cbo_t3
POSTHOOK: query: DROP TABLE IF EXISTS cbo_t3
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@cbo_t3
POSTHOOK: Output: default@cbo_t3
PREHOOK: query: DROP TABLE IF EXISTS src_cbo
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@src_cbo
PREHOOK: Output: default@src_cbo
POSTHOOK: query: DROP TABLE IF EXISTS src_cbo
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@src_cbo
POSTHOOK: Output: default@src_cbo
PREHOOK: query: DROP TABLE IF EXISTS part
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@part
PREHOOK: Output: default@part
POSTHOOK: query: DROP TABLE IF EXISTS part
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@part
POSTHOOK: Output: default@part
PREHOOK: query: DROP TABLE IF EXISTS lineitem
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@lineitem
PREHOOK: Output: default@lineitem
POSTHOOK: query: DROP TABLE IF EXISTS lineitem
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@lineitem
POSTHOOK: Output: default@lineitem
